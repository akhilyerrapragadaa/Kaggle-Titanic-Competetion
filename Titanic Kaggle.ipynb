{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender_submission = [PassengerId: int, Survived: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val gender_submission = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test = [PassengerId: int, Pclass: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Pclass: int ... 9 more fields]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/test.csv\")\n",
    "\n",
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanValue = 29.69911764705882\n",
       "fixedDf = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val meanValue = df.agg(mean(df(\"Age\"))).first.getDouble(0)\n",
    "val fixedDf = df.na.fill(meanValue, Array(\"Age\", \"Embarked\", \"Cabin\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "renamedDF = [PassengerId: int, label: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, label: int ... 10 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val renamedDF = fixedDf.withColumnRenamed(\"Survived\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colLabel = label\n",
       "colCat = Sex\n",
       "ticketcol = Ticket\n",
       "namecol = Name\n",
       "cabinfilter = Cabin\n",
       "embarkedfilter = Embarked\n",
       "colNum = Array(PassengerId, Pclass, Age, SibSp, Parch, Fare)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(PassengerId, Pclass, Age, SibSp, Parch, Fare)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// label columns\n",
    "val colLabel = \"label\"\n",
    "\n",
    "// categorical columns\n",
    "val colCat = \"Sex\"\n",
    "\n",
    "val ticketcol = \"Ticket\"\n",
    "\n",
    "val namecol = \"Name\"\n",
    "\n",
    "val cabinfilter = \"Cabin\"\n",
    "\n",
    "val embarkedfilter = \"Embarked\"\n",
    "\n",
    "// numerical columns\n",
    "val colNum = renamedDF.columns.filter(_ != colLabel).filter(_ != colCat).filter(_ != ticketcol).filter(_ != namecol).filter(_ != embarkedfilter).filter(_ != cabinfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in column PassengerId: 0\n",
      "Number of missing values in column Pclass: 0\n",
      "Number of missing values in column Age: 0\n",
      "Number of missing values in column SibSp: 0\n",
      "Number of missing values in column Parch: 0\n",
      "Number of missing values in column Fare: 0\n"
     ]
    }
   ],
   "source": [
    "for (c <- colNum) {\n",
    "    val count_missing_values = renamedDF.filter(s\"${c} is null\").count()\n",
    "    println(s\"Number of missing values in column ${c}: ${count_missing_values}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+--------------------+\n",
      "|PassengerId|label|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|            features|      scaledFeatures|\n",
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+--------------------+\n",
      "|          1|    0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|[1.0,3.0,22.0,1.0...|[-1.7291368044688...|\n",
      "|          2|    1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|[2.0,1.0,38.0,1.0...|[-1.7252511037846...|\n",
      "|          3|    1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|[3.0,3.0,26.0,0.0...|[-1.7213654031004...|\n",
      "|          4|    1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|[4.0,1.0,35.0,1.0...|[-1.7174797024162...|\n",
      "|          5|    0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|[5.0,3.0,35.0,0.0...|[-1.7135940017320...|\n",
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "va = vecAssembler_63cb1c13ccf4\n",
       "featuredHousing = [PassengerId: int, label: int ... 11 more fields]\n",
       "scaler = stdScal_70334163b856\n",
       "scaledHousing = [PassengerId: int, label: int ... 12 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, label: int ... 12 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{VectorAssembler, StandardScaler}\n",
    "\n",
    "val va = new VectorAssembler()  \n",
    "    .setInputCols(colNum)\n",
    "    .setOutputCol(\"features\")\n",
    "val featuredHousing = va.transform(renamedDF)\n",
    "\n",
    "\n",
    "\n",
    "val scaler = new StandardScaler()\n",
    "    .setInputCol(\"features\")\n",
    "    .setOutputCol(\"scaledFeatures\")\n",
    "    .setWithStd(true)\n",
    "    .setWithMean(true)\n",
    "val scaledHousing = scaler.fit(featuredHousing).transform(featuredHousing)\n",
    "\n",
    "scaledHousing.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.OneHotEncoderEstimator\n",
    "\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "\n",
    "import org.apache.spark.ml.PipelineStage\n",
    "\n",
    "import org.apache.spark.ml.regression.RandomForestRegressor\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sexIndexer = strIdx_6c2507d9e49e\n",
       "ticketIndexer = strIdx_ba2a161078da\n",
       "nameIndexer = strIdx_b8b8f382256c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "strIdx_b8b8f382256c"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "\n",
    "\n",
    "val sexIndexer = new StringIndexer().setInputCol(\"Sex\").setOutputCol(\"Sex_index\")\n",
    "\n",
    "val ticketIndexer = new StringIndexer().setInputCol(\"Ticket\").setOutputCol(\"Ticket_index\")\n",
    "\n",
    "val nameIndexer = new StringIndexer().setInputCol(\"Name\").setOutputCol(\"Name_index\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+--------------------+---------+------------+----------+-------------+-----------------+-----------------+\n",
      "|PassengerId|label|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|            features|      scaledFeatures|Sex_index|Ticket_index|Name_index|Sex_index_Vec| Ticket_index_Vec|   Name_index_Vec|\n",
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+--------------------+---------+------------+----------+-------------+-----------------+-----------------+\n",
      "|          1|    0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|[1.0,3.0,22.0,1.0...|[-1.7291368044688...|      0.0|       257.0|     329.0|(1,[0],[1.0])|(680,[257],[1.0])|(890,[329],[1.0])|\n",
      "|          2|    1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|[2.0,1.0,38.0,1.0...|[-1.7252511037846...|      1.0|       608.0|     805.0|    (1,[],[])|(680,[608],[1.0])|(890,[805],[1.0])|\n",
      "|          3|    1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|[3.0,3.0,26.0,0.0...|[-1.7213654031004...|      1.0|       292.0|     548.0|    (1,[],[])|(680,[292],[1.0])|(890,[548],[1.0])|\n",
      "|          4|    1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|[4.0,1.0,35.0,1.0...|[-1.7174797024162...|      1.0|        46.0|     482.0|    (1,[],[])| (680,[46],[1.0])|(890,[482],[1.0])|\n",
      "|          5|    0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|[5.0,3.0,35.0,0.0...|[-1.7135940017320...|      0.0|       425.0|      12.0|(1,[0],[1.0])|(680,[425],[1.0])| (890,[12],[1.0])|\n",
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+--------------------+---------+------------+----------+-------------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sex_encoder = oneHotEncoder_2df93762975e\n",
       "ticket_encoder = oneHotEncoder_20b6b78d8081\n",
       "name_encoder = oneHotEncoder_af15d5cb46ce\n",
       "numPipeline = pipeline_a460ed5e43dd\n",
       "catPipeline = pipeline_7760b55d86ef\n",
       "pipeline = pipeline_b18b6732aea7\n",
       "newHousing = [PassengerId: int, label: int ... 18 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, label: int ... 18 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import org.apache.spark.ml.feature.OneHotEncoderEstimator\n",
    "\n",
    "val sex_encoder = new OneHotEncoderEstimator()\n",
    "    .setInputCols(Array(\"Sex_index\"))\n",
    "    .setOutputCols(Array(\"Sex_index_Vec\"))\n",
    "\n",
    "val ticket_encoder = new OneHotEncoderEstimator()\n",
    "    .setInputCols(Array(\"Ticket_index\"))\n",
    "    .setOutputCols(Array(\"Ticket_index_Vec\"))\n",
    "\n",
    "val name_encoder = new OneHotEncoderEstimator()\n",
    "    .setInputCols(Array(\"Name_index\"))\n",
    "    .setOutputCols(Array(\"Name_index_Vec\"))\n",
    "\n",
    "\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel, PipelineStage}\n",
    "\n",
    "val numPipeline = new Pipeline().setStages(Array(va,scaler))\n",
    "val catPipeline = new Pipeline().setStages(Array(sexIndexer,ticketIndexer, nameIndexer, sex_encoder, ticket_encoder, name_encoder))\n",
    "\n",
    "val pipeline = new Pipeline().setStages(Array(numPipeline, catPipeline))\n",
    "val newHousing = pipeline.fit(renamedDF).transform(renamedDF)\n",
    "\n",
    "newHousing.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(1577,[0,1,2,3,4,...|    0|\n",
      "|(1577,[0,1,2,3,4,...|    1|\n",
      "|(1577,[0,1,2,3,4,...|    1|\n",
      "|(1577,[0,1,2,3,4,...|    1|\n",
      "|(1577,[0,1,2,3,4,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newHousing2 = [PassengerId: int, label: int ... 17 more fields]\n",
       "va2 = vecAssembler_23ea40810019\n",
       "dataset = [features: vector, label: int]\n",
       "trainSet = [features: vector, label: int]\n",
       "testSet = [features: vector, label: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[features: vector, label: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//columns for training\n",
    "\n",
    "val newHousing2 = newHousing.drop(\"features\")\n",
    "val va2 = new VectorAssembler().setInputCols(Array(\"scaledFeatures\",\"Sex_index_Vec\",\"Ticket_index_Vec\",\"Name_index_Vec\")).setOutputCol(\"features\")\n",
    "val dataset = va2.transform(newHousing2).select(\"features\", \"label\")\n",
    "\n",
    "dataset.show(5)\n",
    "\n",
    "val Array(trainSet, testSet) = dataset.randomSplit(Array(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+\n",
      "|         prediction|label|            features|\n",
      "+-------------------+-----+--------------------+\n",
      "| 0.1438779990889574|    0|(1577,[0,1,2,3,4,...|\n",
      "|0.12102975916817763|    0|(1577,[0,1,2,3,4,...|\n",
      "|0.39306096595838647|    1|(1577,[0,1,2,3,4,...|\n",
      "|0.13977975916817761|    0|(1577,[0,1,2,3,4,...|\n",
      "| 0.1336873856061535|    0|(1577,[0,1,2,3,4,...|\n",
      "+-------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.3709202213797589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rf = rfr_9b524349e423\n",
       "rfModel = RandomForestRegressionModel (uid=rfr_9b524349e423) with 20 trees\n",
       "predictions = [features: vector, label: int ... 1 more field]\n",
       "evaluator = regEval_73b40f4ac369\n",
       "rmse = 0.3709202213797589\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3709202213797589"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rf = new RandomForestRegressor()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setFeaturesCol(\"features\")\n",
    "\n",
    "// train the model\n",
    "val rfModel = rf.fit(trainSet)\n",
    "\n",
    "// make predictions on the test data\n",
    "val predictions = rfModel.transform(testSet)\n",
    "\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "// select (prediction, true label) and compute test error\n",
    "val evaluator = new RegressionEvaluator()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setPredictionCol(\"prediction\")\n",
    "    .setMetricName(\"rmse\")\n",
    "\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "println(s\"Root Mean Squared Error (RMSE) on test data = $rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd = MapPartitionsRDD[165] at map at <console>:42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[165] at map at <console>:42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = predictions.select(\"label\", \"prediction\").rdd.map(row ⇒ (row.getInt(0).toDouble, row.getDouble(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Instantiate metrics object\n",
    "new MulticlassMetrics(rdd).accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
