{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender_submission = [PassengerId: int, Survived: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val gender_submission = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test = [PassengerId: int, Pclass: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Pclass: int ... 9 more fields]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/test.csv\")\n",
    "\n",
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanValue = 29.69911764705882\n",
       "fixedDf = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val meanValue = df.agg(mean(df(\"Age\"))).first.getDouble(0)\n",
    "val fixedDf = df.na.fill(meanValue, Array(\"Age\", \"Embarked\", \"Cabin\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "renamedDF = [PassengerId: int, label: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, label: int ... 10 more fields]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val renamedDF = fixedDf.withColumnRenamed(\"Survived\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colLabel = label\n",
       "colCat = Sex\n",
       "ticketcol = Ticket\n",
       "namecol = Name\n",
       "cabinfilter = Cabin\n",
       "colNum = Array(PassengerId, Pclass, Age, SibSp, Parch, Fare, Embarked)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(PassengerId, Pclass, Age, SibSp, Parch, Fare, Embarked)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// label columns\n",
    "val colLabel = \"label\"\n",
    "\n",
    "// categorical columns\n",
    "val colCat = \"Sex\"\n",
    "\n",
    "val ticketcol = \"Ticket\"\n",
    "\n",
    "val namecol = \"Name\"\n",
    "\n",
    "val cabinfilter = \"Cabin\"\n",
    "\n",
    "val embarkedfilter = \"Embarked\"\n",
    "\n",
    "// numerical columns\n",
    "val colNum = renamedDF.columns.filter(_ != colLabel).filter(_ != colCat).filter(_ != ticketcol).filter(_ != namecol).filter(_ != cabinfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.IllegalArgumentException",
     "evalue": "Data type string of column Embarked is not supported.",
     "output_type": "error",
     "traceback": [
      "java.lang.IllegalArgumentException: Data type string of column Embarked is not supported.",
      "  at org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:169)",
      "  at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)",
      "  at org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:86)",
      "  ... 52 elided"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{VectorAssembler, StandardScaler}\n",
    "\n",
    "val va = new VectorAssembler()  \n",
    "    .setInputCols(colNum)\n",
    "    .setOutputCol(\"features\")\n",
    "val featuredHousing = va.transform(renamedDF)\n",
    "\n",
    "\n",
    "\n",
    "val scaler = new StandardScaler()\n",
    "    .setInputCol(\"features\")\n",
    "    .setOutputCol(\"scaledFeatures\")\n",
    "    .setWithStd(true)\n",
    "    .setWithMean(true)\n",
    "val scaledHousing = scaler.fit(featuredHousing).transform(featuredHousing)\n",
    "\n",
    "scaledHousing.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.OneHotEncoderEstimator\n",
    "\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "\n",
    "import org.apache.spark.ml.PipelineStage\n",
    "\n",
    "import org.apache.spark.ml.regression.RandomForestRegressor\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Name|Name_index|\n",
      "+--------------------+----------+\n",
      "|Madsen, Mr. Fridt...|      15.0|\n",
      "|    Ali, Mr. William|     183.0|\n",
      "|Braund, Mr. Owen ...|     329.0|\n",
      "|Attalah, Mr. Sleiman|     450.0|\n",
      "|Vanden Steen, Mr....|     306.0|\n",
      "|Shellard, Mr. Fre...|     192.0|\n",
      "|Lefebre, Master. ...|     885.0|\n",
      "| Olsson, Miss. Elina|      38.0|\n",
      "|Laitinen, Miss. K...|     642.0|\n",
      "|Allen, Miss. Elis...|     542.0|\n",
      "|\"McGowan, Miss. A...|     417.0|\n",
      "|Hakkarainen, Mrs....|     626.0|\n",
      "| Smiljanic, Mr. Mile|     298.0|\n",
      "|Lurette, Miss. Elise|     739.0|\n",
      "|Sunderland, Mr. V...|      33.0|\n",
      "|Lobb, Mr. William...|     853.0|\n",
      "|Davidson, Mr. Tho...|     871.0|\n",
      "|Vestrom, Miss. Hu...|     491.0|\n",
      "|Nicola-Yarred, Ma...|      89.0|\n",
      "|Cann, Mr. Ernest ...|     765.0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sexIndexer = strIdx_79a3369bcdf7\n",
       "ticketIndexer = strIdx_5d8975418c2c\n",
       "nameIndexer = strIdx_7b013b2d191b\n",
       "sexindexermodel = [PassengerId: int, label: int ... 11 more fields]\n",
       "cabinindexermodel = [PassengerId: int, label: int ... 12 more fields]\n",
       "nameIndexermodel = [PassengerId: int, label: int ... 13 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, label: int ... 13 more fields]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "\n",
    "\n",
    "val sexIndexer = new StringIndexer().setInputCol(\"Sex\").setOutputCol(\"Sex_index\")\n",
    "\n",
    "val ticketIndexer = new StringIndexer().setInputCol(\"Ticket\").setOutputCol(\"Ticket_index\")\n",
    "\n",
    "val nameIndexer = new StringIndexer().setInputCol(\"Name\").setOutputCol(\"Name_index\")\n",
    "\n",
    "\n",
    "\n",
    "val sexindexermodel = sexIndexer.fit(renamedDF).transform(renamedDF)\n",
    "\n",
    "val cabinindexermodel = ticketIndexer.fit(sexindexermodel).transform(sexindexermodel)\n",
    "\n",
    "val nameIndexermodel = nameIndexer.fit(cabinindexermodel).transform(cabinindexermodel)\n",
    "\n",
    "\n",
    "nameIndexermodel.select(\"Name\",\"Name_index\").distinct.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+------------+----------+-------------+-----------------+-----------------+\n",
      "|PassengerId|label|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Sex_index|Ticket_index|Name_index|Sex_index_Vec| Ticket_index_Vec|   Name_index_Vec|\n",
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+------------+----------+-------------+-----------------+-----------------+\n",
      "|          1|    0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|      0.0|       257.0|     329.0|(1,[0],[1.0])|(680,[257],[1.0])|(890,[329],[1.0])|\n",
      "|          2|    1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|      1.0|       608.0|     805.0|    (1,[],[])|(680,[608],[1.0])|(890,[805],[1.0])|\n",
      "|          3|    1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|      1.0|       292.0|     548.0|    (1,[],[])|(680,[292],[1.0])|(890,[548],[1.0])|\n",
      "|          4|    1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|      1.0|        46.0|     482.0|    (1,[],[])| (680,[46],[1.0])|(890,[482],[1.0])|\n",
      "|          5|    0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|      0.0|       425.0|      12.0|(1,[0],[1.0])|(680,[425],[1.0])| (890,[12],[1.0])|\n",
      "+-----------+-----+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+---------+------------+----------+-------------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sex_encoder = oneHotEncoder_1ae840306330\n",
       "ticket_encoder = oneHotEncoder_406415b8d013\n",
       "name_encoder = oneHotEncoder_e08914afebf6\n",
       "ohHousing = [PassengerId: int, label: int ... 14 more fields]\n",
       "hous2 = [PassengerId: int, label: int ... 15 more fields]\n",
       "hous3 = [PassengerId: int, label: int ... 16 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, label: int ... 16 more fields]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import org.apache.spark.ml.feature.OneHotEncoderEstimator\n",
    "\n",
    "val sex_encoder = new OneHotEncoderEstimator()\n",
    "    .setInputCols(Array(\"Sex_index\"))\n",
    "    .setOutputCols(Array(\"Sex_index_Vec\"))\n",
    "\n",
    "val ticket_encoder = new OneHotEncoderEstimator()\n",
    "    .setInputCols(Array(\"Ticket_index\"))\n",
    "    .setOutputCols(Array(\"Ticket_index_Vec\"))\n",
    "\n",
    "val name_encoder = new OneHotEncoderEstimator()\n",
    "    .setInputCols(Array(\"Name_index\"))\n",
    "    .setOutputCols(Array(\"Name_index_Vec\"))\n",
    "\n",
    "\n",
    "val ohHousing = sex_encoder.fit(nameIndexermodel).transform(nameIndexermodel)\n",
    "\n",
    "val hous2 = ticket_encoder.fit(ohHousing).transform(ohHousing)\n",
    "\n",
    "val hous3 = name_encoder.fit(hous2).transform(hous2)\n",
    "\n",
    "hous3.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(1575,[0,258,1010...|    0|\n",
      "|(1575,[609,1486,1...|    1|\n",
      "|(1575,[293,1229,1...|    1|\n",
      "|(1575,[47,1163,15...|    1|\n",
      "|(1575,[0,426,693,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cols = Array(Sex_index_Vec, Ticket_index_Vec, Name_index_Vec, SibSp, Parch, Age, Fare)\n",
       "vectorAssembler = vecAssembler_c61f3d68888a\n",
       "dataset = [features: vector, label: int]\n",
       "trainSet = [features: vector, label: int]\n",
       "testSet = [features: vector, label: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[features: vector, label: int]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//columns for training\n",
    "val cols = Array(\"Sex_index_Vec\", \"Ticket_index_Vec\", \"Name_index_Vec\", \"SibSp\", \"Parch\", \"Age\", \"Fare\")\n",
    "val vectorAssembler = new VectorAssembler().setInputCols(cols).setOutputCol(\"features\")\n",
    "\n",
    "val dataset = vectorAssembler.transform(hous3).select(\"features\", \"label\")\n",
    "\n",
    "dataset.show(5)\n",
    "\n",
    "val Array(trainSet, testSet) = dataset.randomSplit(Array(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+\n",
      "|         prediction|label|            features|\n",
      "+-------------------+-----+--------------------+\n",
      "|0.37352890512010983|    1|(1575,[0,3,1253,1...|\n",
      "|0.16660189865514446|    0|(1575,[0,4,972,15...|\n",
      "| 0.1447217511125361|    0|(1575,[0,6,856,15...|\n",
      "|0.17091013435514188|    0|(1575,[0,7,735,15...|\n",
      "|0.14146033364263472|    0|(1575,[0,11,1052,...|\n",
      "+-------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.43540880600366866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rf = rfr_e123390523a3\n",
       "rfModel = RandomForestRegressionModel (uid=rfr_e123390523a3) with 20 trees\n",
       "predictions = [features: vector, label: int ... 1 more field]\n",
       "evaluator = regEval_f1b7867236a4\n",
       "rmse = 0.43540880600366866\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.43540880600366866"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rf = new RandomForestRegressor()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setFeaturesCol(\"features\")\n",
    "\n",
    "// train the model\n",
    "val rfModel = rf.fit(trainSet)\n",
    "\n",
    "// make predictions on the test data\n",
    "val predictions = rfModel.transform(testSet)\n",
    "\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "// select (prediction, true label) and compute test error\n",
    "val evaluator = new RegressionEvaluator()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setPredictionCol(\"prediction\")\n",
    "    .setMetricName(\"rmse\")\n",
    "\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "println(s\"Root Mean Squared Error (RMSE) on test data = $rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdd = MapPartitionsRDD[1544] at map at <console>:129\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[1544] at map at <console>:129"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = predictions.select(\"label\", \"prediction\").rdd.map(row â‡’ (row.getInt(0).toDouble, row.getDouble(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Instantiate metrics object\n",
    "new MulticlassMetrics(rdd).accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
