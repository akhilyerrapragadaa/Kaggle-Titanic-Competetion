{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.OneHotEncoderEstimator\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.feature.{IndexToString, VectorIndexer}\n",
    "import org.apache.spark.ml.PipelineStage\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender_submission = [PassengerId: int, Survived: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val gender_submission = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test = [PassengerId: int, Pclass: int ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Pclass: int ... 9 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/test.csv\")\n",
    "\n",
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agemeanValue = 29.69911764705882\n",
       "faremeanValue = 32.2042079685746\n",
       "fixedDf = [PassengerId: int, Survived: int ... 10 more fields]\n",
       "reFixed = [PassengerId: int, Survived: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, Survived: int ... 10 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val agemeanValue = df.agg(mean(df(\"Age\"))).first.getDouble(0)\n",
    "\n",
    "val faremeanValue = df.agg(mean(df(\"Fare\"))).first.getDouble(0)\n",
    "\n",
    "val fixedDf = df.na.fill(agemeanValue, Array(\"Age\"))\n",
    "\n",
    "val reFixed = fixedDf.na.fill(agemeanValue, Array(\"Fare\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recvTrainData = [PassengerId: int, Survived: int ... 10 more fields]\n",
       "recvTestData = [PassengerId: int, Survived: int ... 10 more fields]\n",
       "trainingData = [PassengerId: int, label: int ... 10 more fields]\n",
       "testData = [PassengerId: int, label: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PassengerId: int, label: int ... 10 more fields]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(recvTrainData, recvTestData) = reFixed.randomSplit(Array(0.8, 0.2))\n",
    "\n",
    "val trainingData = recvTrainData.withColumnRenamed(\"Survived\", \"label\")\n",
    "\n",
    "val testData = recvTestData.withColumnRenamed(\"Survived\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cols = Array(Sex, Pclass)\n",
       "stringIndexers = Array(Sex, Pclass)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(Sex, Pclass)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cols = Array(\"Sex\", \"Pclass\")\n",
    "val stringIndexers = cols.map { eachCol =>\n",
    "  new StringIndexer(eachCol)\n",
    "    .setInputCol(eachCol)\n",
    "    .setOutputCol(eachCol + \"_Indexed\")\n",
    "    .fit(trainingData)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cols = Array(Fare, Age, SibSp, Parch, Pclass_Indexed, Sex_Indexed)\n",
       "assembler = vecAssembler_9af1fd261440\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vecAssembler_9af1fd261440"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cols = Array(\"Fare\", \"Age\", \"SibSp\", \"Parch\", \"Pclass_Indexed\", \"Sex_Indexed\")\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(cols)\n",
    "  .setOutputCol(\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "randomForest = rfc_f3469863e9ff\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "rfc_f3469863e9ff"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val randomForest = new RandomForestClassifier()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setFeaturesCol(\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline = pipeline_b75dd74f59bb\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_b75dd74f59bb"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline().setStages((stringIndexers :+ assembler :+ randomForest ).toArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paramGrid = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array({\n",
       "\trfc_f3469863e9ff-impurity: entropy,\n",
       "\trfc_f3469863e9ff-maxBins: 23,\n",
       "\trfc_f3469863e9ff-maxDepth: 4\n",
       "}, {\n",
       "\trfc_f3469863e9ff-impurity: entropy,\n",
       "\trfc_f3469863e9ff-maxBins: 29,\n",
       "\trfc_f3469863e9ff-maxDepth: 4\n",
       "}, {\n",
       "\trfc_f3469863e9ff-impurity: entropy,\n",
       "\trfc_f3469863e9ff-maxBins: 31,\n",
       "\trfc_f3469863e9ff-maxDepth: 4\n",
       "}, {\n",
       "\trfc_f3469863e9ff-impurity: entropy,\n",
       "\trfc_f3469863e9ff-maxBins: 23,\n",
       "\trfc_f3469863e9ff-maxDepth: 6\n",
       "}, {\n",
       "\trfc_f3469863e9ff-impurity: entropy,\n",
       "\trfc_f3469863e9ff-maxBins: 29,\n",
       "\trfc_f3469863e9ff-maxDepth: 6\n",
       "}, {\n",
       "\trfc_f3469863e9ff-impurity: entropy,\n",
       "\trfc_f3469863e9ff-maxBins: 31,\n",
       "\trfc_f3469863e9ff-maxDepth: 6\n",
       "}, {\n",
       "\trfc_f3469863e9ff-impurity: entropy,\n",
       "\trfc_f3469863e9ff-maxBins: 23,\n",
       "\trfc_f3469863e9ff-maxDepth: 8\n",
       "}, {\n",
       "\trfc_f3469863...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val paramGrid = new ParamGridBuilder()\n",
    "      .addGrid(randomForest.maxBins, Array(23, 29, 31))\n",
    "      .addGrid(randomForest.maxDepth, Array(4, 6, 8))\n",
    "      .addGrid(randomForest.impurity, Array(\"entropy\", \"gini\"))\n",
    "      .build()\n",
    "\n",
    "val evaluator = new BinaryClassificationEvaluator()\n",
    "        .setLabelCol(\"label\")\n",
    "\n",
    "val cv = new CrossValidator()\n",
    "      .setEstimator(pipeline)\n",
    "      .setEvaluator(evaluator)\n",
    "      .setEstimatorParamMaps(paramGrid)\n",
    "      .setNumFolds(10)\n",
    "\n",
    "    // train the model\n",
    "val crossValidatorModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions = [PassengerId: int, label: int ... 16 more fields]\n",
       "accuracy = 0.8923680361654037\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8923680361654037"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = crossValidatorModel.transform(testData)\n",
    "\n",
    "val accuracy = evaluator.evaluate(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
